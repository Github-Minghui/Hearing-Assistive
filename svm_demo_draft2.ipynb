{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hearing_assistive import *\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Waves and Assign Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fire_alarm = read_wave('Sounds/school_fire_alarm.wav')\n",
    "fire_alarm_target = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MFCC Features, Create Training Dataset, and Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# partition wave into segments ( default is 2.4 seconds )\n",
    "seg_map = fire_alarm.partition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# initialize SVM classifier\n",
    "clf = linear_model.SGDClassifier()   # linear SVM classifier with Stochastic Gradient Descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "(300, 1547)\n",
      "300\n",
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: MAKE THIS CELL A MODULE FUNCTION\n",
    "# create and train dummyset\n",
    "dataset = []\n",
    "targetset = []\n",
    "size = 100\n",
    "\n",
    "# add (e.g. 100) dummy sets of zeros to the dataset\n",
    "for i in range(size):\n",
    "    dummyset = np.zeros((119, 13))\n",
    "    dataset.append(dummyset)\n",
    "    targetset.append(0)\n",
    "    \n",
    "# add (e.g. 100) dummy sets of ones to the dataset\n",
    "for i in range(size):\n",
    "    dummyset = np.ones((119, 13))\n",
    "    dataset.append(dummyset)\n",
    "    targetset.append(1)\n",
    "    \n",
    "# add (e.g. 100) dummy sets of negative ones to the dataset\n",
    "for i in range(size):\n",
    "    dummyset = np.negative(np.ones((119, 13)))\n",
    "    dataset.append(dummyset)\n",
    "    targetset.append(2)\n",
    "    \n",
    "# convert to numpy arrays\n",
    "dataset = np.asarray(dataset)\n",
    "targetset = np.asarray(targetset)\n",
    "    \n",
    "# restructure dataset before being processed by svm\n",
    "dataset = dataset.reshape((dataset.shape[0], -1))\n",
    "\n",
    "print len(dataset)\n",
    "print dataset.shape\n",
    "print len(targetset)\n",
    "print targetset.shape\n",
    "    \n",
    "# train dummyset\n",
    "clf.fit(dataset, targetset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (100, 119, 13) (100,)\n",
      "1 (100, 119, 13) (100,)\n",
      "2 (100, 119, 13) (100,)\n",
      "3 (100, 119, 13) (100,)\n",
      "4 (100, 119, 13) (100,)\n",
      "5 (100, 119, 13) (100,)\n",
      "6 (100, 119, 13) (100,)\n",
      "7 (100, 119, 13) (100,)\n",
      "8 (100, 119, 13) (100,)\n",
      "9 (100, 119, 13) (100,)\n",
      "10 (100, 119, 13) (100,)\n",
      "11 (100, 119, 13) (100,)\n",
      "12 (100, 119, 13) (100,)\n",
      "13 (100, 119, 13) (100,)\n",
      "14 (100, 119, 13) (100,)\n",
      "15 (100, 119, 13) (100,)\n",
      "16 (100, 119, 13) (100,)\n",
      "17 (100, 119, 13) (100,)\n",
      "18 (100, 119, 13) (100,)\n",
      "19 (100, 119, 13) (100,)\n",
      "20 (100, 119, 13) (100,)\n",
      "21 (100, 119, 13) (100,)\n"
     ]
    }
   ],
   "source": [
    "# create a dataset for each 2.4s-segment and feed each dataset into the SVM classifier\n",
    "for i in range(len(seg_map)):\n",
    "    # initialize dataset and targetset\n",
    "    dataset = []\n",
    "    targetset = []\n",
    "    \n",
    "    # get segment from seg_map\n",
    "    segment = seg_map[i]\n",
    "    \n",
    "    # generate samples with added noise ( default is 100 samples ) and extract mfccs\n",
    "    dataset, targetset = generate_feature_set(segment, fire_alarm_target)\n",
    "    print i, dataset.shape, targetset.shape\n",
    "    \n",
    "    # restructure dataset before being processed by svm\n",
    "    dataset = dataset.reshape((dataset.shape[0], -1))\n",
    "    \n",
    "    # fit classifier with dataset and corresponding targetset\n",
    "    clf.partial_fit(dataset, targetset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Testing Dataset and Test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1547)\n"
     ]
    }
   ],
   "source": [
    "testset = []\n",
    "size = 2\n",
    "\n",
    "# add dummy sets of zeros to the testset\n",
    "for i in range(size):\n",
    "    dummyset = np.zeros((119, 13))\n",
    "    testset.append(dummyset)\n",
    "    \n",
    "# add dummy sets of ones to the testset\n",
    "for i in range(size):\n",
    "    dummyset = np.ones((119, 13))\n",
    "    testset.append(dummyset)\n",
    "    \n",
    "# add dummy sets of negative ones to the testset\n",
    "for i in range(size):\n",
    "    dummyset = np.negative(np.ones((119, 13)))\n",
    "    testset.append(dummyset)\n",
    "    \n",
    "# # add alarm sound files to the testset\n",
    "# for i in range(size):\n",
    "#     segment = seg_map[10]\n",
    "#     spectrogram = segment.make_spectrogram(seg_length=1764)  # 1764 = 40ms * 44100fps = samples per 40ms\n",
    "#     dummyset = spectrogram.mfcc()   # use default parameter, only include coefficients 2-14 (13 coefficients)\n",
    "#     testset.append(dummyset)\n",
    "    \n",
    "    \n",
    "# convert to numpy array\n",
    "testset = np.asarray(testset)\n",
    "    \n",
    "# restructure testset before being processed by svm\n",
    "testset = testset.reshape((testset.shape[0], -1))\n",
    "print testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extected: [0, 0, 1, 1, 2, 2, 3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"extected: [0, 0, 1, 1, 2, 2, 3, 3]\"\n",
    "clf.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
